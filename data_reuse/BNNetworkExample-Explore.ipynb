{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "weighted-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.factors.discrete import TabularCPD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "excited-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianModel([('D', 'G'), ('I', 'G'), ('G', 'L'), ('I', 'S')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "touched-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_d = TabularCPD(variable='D', variable_card=2, values=[[0.6], [0.4]])\n",
    "cpd_i = TabularCPD(variable='I', variable_card=2, values=[[0.7], [0.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liable-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_g = TabularCPD(variable='G', variable_card=3, \n",
    "                   values=[[0.3, 0.05, 0.9,  0.5],\n",
    "                           [0.4, 0.25, 0.08, 0.3],\n",
    "                           [0.3, 0.7,  0.02, 0.2]],\n",
    "                  evidence=['I', 'D'],\n",
    "                  evidence_card=[2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "infinite-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_l = TabularCPD(variable='L', variable_card=2, \n",
    "                   values=[[0.1, 0.4, 0.99],\n",
    "                           [0.9, 0.6, 0.01]],\n",
    "                   evidence=['G'],\n",
    "                   evidence_card=[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "manufactured-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_s = TabularCPD(variable='S', variable_card=2,\n",
    "                   values=[[0.95, 0.2],\n",
    "                           [0.05, 0.8]],\n",
    "                   evidence=['I'],\n",
    "                   evidence_card=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "central-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_cpds(cpd_d, cpd_i, cpd_g, cpd_l, cpd_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fitted-comparative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.check_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adjacent-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_d_sn = TabularCPD(variable='D', variable_card=2, values=[[0.6], [0.4]], state_names={'D': ['Easy', 'Hard']})\n",
    "cpd_i_sn = TabularCPD(variable='I', variable_card=2, values=[[0.7], [0.3]], state_names={'I': ['Dumb', 'Intelligent']})\n",
    "cpd_g_sn = TabularCPD(variable='G', variable_card=3, \n",
    "                      values=[[0.3, 0.05, 0.9,  0.5],\n",
    "                              [0.4, 0.25, 0.08, 0.3],\n",
    "                              [0.3, 0.7,  0.02, 0.2]],\n",
    "                      evidence=['I', 'D'],\n",
    "                      evidence_card=[2, 2],\n",
    "                      state_names={'G': ['A', 'B', 'C'],\n",
    "                                   'I': ['Dumb', 'Intelligent'],\n",
    "                                   'D': ['Easy', 'Hard']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "junior-symposium",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_l_sn = TabularCPD(variable='L', variable_card=2, \n",
    "                      values=[[0.1, 0.4, 0.99],\n",
    "                              [0.9, 0.6, 0.01]],\n",
    "                      evidence=['G'],\n",
    "                      evidence_card=[3],\n",
    "                      state_names={'L': ['Bad', 'Good'],\n",
    "                                   'G': ['A', 'B', 'C']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "respected-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_s_sn = TabularCPD(variable='S', variable_card=2,\n",
    "                      values=[[0.95, 0.2],\n",
    "                              [0.05, 0.8]],\n",
    "                      evidence=['I'],\n",
    "                      evidence_card=[2],\n",
    "                      state_names={'S': ['Bad', 'Good'],\n",
    "                                   'I': ['Dumb', 'Intelligent']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "decreased-sigma",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for D\n",
      "WARNING:root:Replacing existing CPD for I\n",
      "WARNING:root:Replacing existing CPD for G\n",
      "WARNING:root:Replacing existing CPD for L\n",
      "WARNING:root:Replacing existing CPD for S\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add_cpds(cpd_d_sn, cpd_i_sn, cpd_g_sn, cpd_l_sn, cpd_s_sn)\n",
    "model.check_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "measured-deadline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<TabularCPD representing P(D:2) at 0x198ba7e1220>,\n",
       " <TabularCPD representing P(I:2) at 0x198ba7e11c0>,\n",
       " <TabularCPD representing P(G:3 | I:2, D:2) at 0x198ba7e1250>,\n",
       " <TabularCPD representing P(L:2 | G:3) at 0x1989ce64b50>,\n",
       " <TabularCPD representing P(S:2 | I:2) at 0x198ba7bacd0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_cpds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "victorian-watershed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+------+\n",
      "| I    | I(0) | I(0) | I(1) | I(1) |\n",
      "+------+------+------+------+------+\n",
      "| D    | D(0) | D(1) | D(0) | D(1) |\n",
      "+------+------+------+------+------+\n",
      "| G(0) | 0.3  | 0.05 | 0.9  | 0.5  |\n",
      "+------+------+------+------+------+\n",
      "| G(1) | 0.4  | 0.25 | 0.08 | 0.3  |\n",
      "+------+------+------+------+------+\n",
      "| G(2) | 0.3  | 0.7  | 0.02 | 0.2  |\n",
      "+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "print(cpd_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sound-washer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------+----------------+----------------+\n",
      "| I    | I(Dumb) | I(Dumb) | I(Intelligent) | I(Intelligent) |\n",
      "+------+---------+---------+----------------+----------------+\n",
      "| D    | D(Easy) | D(Hard) | D(Easy)        | D(Hard)        |\n",
      "+------+---------+---------+----------------+----------------+\n",
      "| G(A) | 0.3     | 0.05    | 0.9            | 0.5            |\n",
      "+------+---------+---------+----------------+----------------+\n",
      "| G(B) | 0.4     | 0.25    | 0.08           | 0.3            |\n",
      "+------+---------+---------+----------------+----------------+\n",
      "| G(C) | 0.3     | 0.7     | 0.02           | 0.2            |\n",
      "+------+---------+---------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print(model.get_cpds('G'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "superb-avatar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_cardinality('G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "forced-auction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(G ⟂ S | I, D)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.local_independencies('G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "destroyed-filter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(D ⟂ S, I)\n",
       "(I ⟂ D)\n",
       "(S ⟂ G, L, D | I)\n",
       "(G ⟂ S | I, D)\n",
       "(L ⟂ S, I, D | G)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.local_independencies(['D', 'I', 'S', 'G', 'L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accomplished-pierre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': {'D', 'G', 'L'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.active_trail_nodes('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "supposed-indiana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': {'D', 'I', 'S'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.active_trail_nodes('D', observed='G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "modular-exposure",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: :   0%|                                                               | 0/4 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Eliminating: S:   0%|                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Eliminating: I:   0%|                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Eliminating: L:   0%|                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Eliminating: D: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 572.99it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "| G    |   phi(G) |\n",
      "+======+==========+\n",
      "| G(A) |   0.3620 |\n",
      "+------+----------+\n",
      "| G(B) |   0.2884 |\n",
      "+------+----------+\n",
      "| G(C) |   0.3496 |\n",
      "+------+----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.inference import VariableElimination\n",
    "infer = VariableElimination(model)\n",
    "g_dist = infer.query(['G'])\n",
    "print(g_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "voluntary-hayes",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Finding Elimination Order: :   0%|                                                               | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Eliminating: S:   0%|                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Eliminating: L:   0%|                                                                            | 0/2 [00:10<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Finding Elimination Order: : 100%|███████████████████████████████████████████████████████| 4/4 [01:00<00:00, 15.02s/it]\u001b[A\u001b[A\n",
      "Eliminating: L: 100%|████████████████████████████████████████████████████████████████████| 2/2 [01:10<00:00, 35.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "| G    |   phi(G) |\n",
      "+======+==========+\n",
      "| G(A) |   0.9000 |\n",
      "+------+----------+\n",
      "| G(B) |   0.0800 |\n",
      "+------+----------+\n",
      "| G(C) |   0.0200 |\n",
      "+------+----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding Elimination Order: : 100%|███████████████████████████████████████████████████████| 2/2 [01:20<00:00, 40.05s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(infer.query(['G'], evidence={'D': 'Easy', 'I': 'Intelligent'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "spanish-draft",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: :   0%|                                                               | 0/4 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Eliminating: S:   0%|                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Eliminating: I:   0%|                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Eliminating: L:   0%|                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Eliminating: D: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 498.73it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'G': 'A'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer.map_query(['G'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The IDE that I run this on is Spyder, not notebooks. PyAgrum is a framework I use for this\n",
    "import pyAgrum as gum\n",
    "\n",
    "# Iniialize the Bayesian Network\n",
    "bn = gum.BayesNet('MyNetwork')\n",
    "#the nodes\n",
    "Exam = bn.add(gum.LabelizedVariable('Exam', 'Test Variable1', 2))\n",
    "T2 = bn.add(gum.LabelizedVariable('T2', 'Testvariable 2', 2))\n",
    "T3 = bn.add(gum.LabelizedVariable('T3', 'Test Variable 3', 2))\n",
    "W = bn.add(gum.LabelizedVariable('T4','Test Variable 4',2))\n",
    "\n",
    "#edges\n",
    "\n",
    "for link in [(T1,T2), (T2,T3), (T1,T3)]:\n",
    "    bn.addArc(*link)\n",
    "#define conditional probbilities\n",
    "#all of these need to be informed by literature\n",
    "bn.cpt(Exam)[:] = [0.2, 0.8]\n",
    "bn.cpt(T2)[0, :] = [0.4, 0.6]\n",
    "bn.cpt(T2)[1, :] = [0.01, 0.99]\n",
    "bn.cpt(T3)[{'Exam':0,'T2': 0}] = [0.0, 1.0]\n",
    "bn.cpt(T3)[{'Exam':0,'T2': 1}] = [0.8, 1.2]\n",
    "bn.cpt(T3)[{'Exam':1,'T2': 0}] = [0.9, 0.1]\n",
    "bn.cpt(T3)[{'Exam':1,'T2': 1}] = [0.99, 0.01]\n",
    "\n",
    "#the function in the package\n",
    "dbg = gum.BNDatabaseGenerator(bn)\n",
    "\n",
    "#Optimal sample size needs to be determined\n",
    "dbg.drawSamples(100)\n",
    "#csv of code\n",
    "dbg.toCSV('FakeDB.csv')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn2 = gum.BayesNet('TestNetwork')\n",
    "Examlevel = bn2.add(gum.LabelizedVariable('Examlevel', 'Variable1', 2))\n",
    "IQlevel = bn2.add(gum.LabelizedVariable('IQlevel','Variable2',2))\n",
    "Marks = bn2.add(gum.LabelizedVariable('Marks','Variable3',2))\n",
    "Aptiscore = bn2.add(gum.LabelizedVariable('Aptiscore','Variable4',4))\n",
    "Admission = bn2.add(gum.LabelizedVariable('Admission','Variable5',4))\n",
    "\n",
    "bn2 = gum.fastBN(\"Examlevel->Marks<-IQlevel->Aptiscore;Marks->Admission\")\n",
    "\n",
    "#the first set of cariables that lead to marks\n",
    "bn2.cpt('IQlevel')[:] = [0.8, 0.2]\n",
    "\n",
    "bn2.cpt('Examlevel')[:] = [0.7, 0.36]\n",
    "\n",
    "bn2.cpt('Marks')[{'Examlevel':0, 'IQlevel':0}] = [0.6, 0.4]\n",
    "bn2.cpt('Marks')[{'Examlevel':0, 'IQlevel':1}] = [0.9, 0.1]\n",
    "bn2.cpt('Marks')[{'Examlevel':1, 'IQlevel':0}] = [0.5, 0.5]\n",
    "bn2.cpt('Marks')[{'Examlevel':1, 'IQlevel':0}] = [0.8, 0.2]\n",
    "\n",
    "#the second set of variables that lead to admission given marks\n",
    "bn2.cpt('Admission')[{'Marks':0}] = [0.6, 0.4]\n",
    "bn2.cpt('Admission')[{'Marks':1}] = [0.9, 0.1]\n",
    "\n",
    "#the indepenand node IQ that leads to APtiscore\n",
    "bn2.cpt('Aptiscore')[{'IQlevel':0}] = [0.75, 0.25]\n",
    "bn2.cpt('Aptiscore')[{'IQlevel':1}] = [0.4, 0.6]\n",
    "\n",
    "\n",
    "dbg = gum.BNDatabaseGenerator(bn2)\n",
    "dbg.drawSamples(100)\n",
    "dbg.toCSV('Mytest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pyAgrum as gum\n",
    "\n",
    "#declare the network \"ConvBN\", for this case call it the \"TestNetwork\"\n",
    "ConvBN = gum.BayesNet('TestNetwork')\n",
    "\n",
    "#declare all the different variables in the ConvBN network\n",
    "Examlevel = ConvBN.add(gum.LabelizedVariable('Examlevel', 'Variable1', 2))\n",
    "IQlevel = ConvBN.add(gum.LabelizedVariable('IQlevel','Variable2',2))\n",
    "Marks = ConvBN.add(gum.LabelizedVariable('Marks','Variable3',2))\n",
    "Aptiscore = ConvBN.add(gum.LabelizedVariable('Aptiscore','Variable4',8))\n",
    "Admission = ConvBN.add(gum.LabelizedVariable('Admission','Variable5',4))\n",
    "\n",
    "#define the structure of the nodes. Note that the node \"Marks to Admission\" is seperate\n",
    "ConvBN = gum.fastBN(\"Examlevel->Marks<-IQlevel->Aptiscore ; Marks->Admission\")\n",
    "\n",
    "#the top most independent nodes, \"Exam level\" and \"IQ level\"\n",
    "ConvBN.cpt('IQlevel')[:] = [0.8, 0.2]\n",
    "ConvBN.cpt('Examlevel')[:] = [0.7, 0.36]\n",
    "\n",
    "#The \"Marks\" as a result of \"IQ level\" and \"Exam level\"\n",
    "ConvBN.cpt('Marks')[{'Examlevel':0, 'IQlevel':0}] = [0.6, 0.4]\n",
    "ConvBN.cpt('Marks')[{'Examlevel':0, 'IQlevel':1}] = [0.9, 0.1]\n",
    "ConvBN.cpt('Marks')[{'Examlevel':1, 'IQlevel':0}] = [0.5, 0.5]\n",
    "ConvBN.cpt('Marks')[{'Examlevel':1, 'IQlevel':0}] = [0.8, 0.2]\n",
    "\n",
    "#the second set of variables that lead to \"Admission\" given \"Marks\"\n",
    "ConvBN.cpt('Admission')[{'Marks':0}] = [0.6, 0.4]\n",
    "ConvBN.cpt('Admission')[{'Marks':1}] = [0.9, 0.1]\n",
    "\n",
    "#the indepenand node \"APtiscore\" given \"IQ level\"\n",
    "ConvBN.cpt('Aptiscore')[{'IQlevel':0}] = [0.75, 0.25]\n",
    "ConvBN.cpt('Aptiscore')[{'IQlevel':1}] = [0.4, 0.6]\n",
    "\n",
    "#A very neat function of the PyAgrum library is database generation\n",
    "dbg = gum.BNDatabaseGenerator(ConvBN)\n",
    "\n",
    "#declare number of samples in the dataset\n",
    "dbg.drawSamples(1000)\n",
    "\n",
    "W\n",
    "dbg.toCSV('GenerateFakedatabasedonnetwork.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
